Check for New Records:
SELECT *
FROM dimension_table
WHERE update_date > 'last_validation_date'
Check for Deleted Records:
SELECT *
FROM reference_table
WHERE NOT EXISTS (
    SELECT 1
    FROM dimension_table
    WHERE dimension_table.key_column = reference_table.key_column
)
Check for Updates:
SELECT
    dimension_table.key_column,
    dimension_table.column1,
    dimension_table.column2
FROM
    dimension_table
JOIN
    reference_table ON dimension_table.key_column = reference_table.key_column
WHERE
    dimension_table.column1 <> reference_table.column1
    OR dimension_table.column2 <> reference_table.column2


SELECT *
FROM dimension_table
WHERE required_field1 IS NULL OR required_field1 = ''
   OR required_field2 IS NULL OR required_field2 = ''
   -- Add additional conditions for other required fields


Check for Missing Dimension Records:
SELECT *
FROM fact_table f
LEFT JOIN dimension_table d ON f.dimension_key = d.dimension_key
WHERE d.dimension_key IS NULL


Check for Inactive Dimension Records:
SELECT *
FROM fact_table f
JOIN dimension_table d ON f.dimension_key = d.dimension_key
WHERE d.status = 'inactive'


Check for Consistency in Dimension Keys:
SELECT *
FROM fact_table f
LEFT JOIN dimension_table d ON f.dimension_key = d.dimension_key
WHERE f.dimension_key IS NOT NULL
  AND d.dimension_key IS NULL


Check for Inconsistent Dimension Keys:
SELECT
  f.dimension_key,
  f.column1,
  f.column2
FROM
  fact_table f
LEFT JOIN
  dimension_table d ON f.dimension_key = d.dimension_key
WHERE
  f.column1 <> d.column1
  OR f.column2 <> d.column2


Check for Referential Integrity:
SELECT *
FROM fact_table f
WHERE NOT EXISTS (
  SELECT 1
  FROM dimension_table d
  WHERE f.dimension_key = d.dimension_key
)



Check for Missing Dimension Attributes:
SELECT *
FROM dimension_table d
WHERE NOT EXISTS (
  SELECT 1
  FROM fact_table f
  WHERE f.dimension_key = d.dimension_key
    AND (f.attribute1 IS NOT NULL OR f.attribute2 IS NOT NULL)
)


Check for Invalid Dimension Keys:
SELECT *
FROM fact_table f
LEFT JOIN dimension_table d ON f.dimension_key = d.dimension_key
WHERE f.dimension_key IS NOT NULL AND d.dimension_key IS NULL



Check for Missing Dimension Attributes:
SELECT *
FROM dimension_table d
WHERE NOT EXISTS (
  SELECT 1
  FROM fact_table f
  WHERE f.dimension_key = d.dimension_key
    AND (f.attribute1 IS NOT NULL OR f.attribute2 IS NOT NULL)
)






-- Table to store table names
CREATE TABLE table_names (
  table_name VARCHAR
);

-- Table to store column names
CREATE TABLE column_names (
  table_name VARCHAR,
  column_name VARCHAR
);



-- Insert table names
INSERT INTO table_names (table_name)
VALUES ('source_table'), ('target_table');

-- Insert column names for source_table
INSERT INTO column_names (table_name, column_name)
VALUES ('source_table', 'column1'), ('source_table', 'column2');

-- Insert column names for target_table
INSERT INTO column_names (table_name, column_name)
VALUES ('target_table', 'column1'), ('target_table', 'column2');



CREATE OR REPLACE PROCEDURE VALIDATE_INSERT_UPDATE_RECORDS()
RETURNS VARIANT
LANGUAGE SQL
AS
$$
DECLARE
  target_hashes VARIANT;
  source_hashes VARIANT;
  insert_records VARIANT;
  update_records VARIANT;
BEGIN
  -- Retrieve table names
  target_table_name := (
    SELECT table_name
    FROM table_names
    WHERE table_name = 'target_table'
  );
  
  source_table_name := (
    SELECT table_name
    FROM table_names
    WHERE table_name = 'source_table'
  );
  
  -- Retrieve column names for target table
  target_column_names := (
    SELECT ARRAY_AGG(column_name)
    FROM column_names
    WHERE table_name = target_table_name
  );
  
  -- Retrieve column names for source table
  source_column_names := (
    SELECT ARRAY_AGG(column_name)
    FROM column_names
    WHERE table_name = source_table_name
  );
  
  -- Generate Hash Key for Target Table
  EXECUTE IMMEDIATE '
    SELECT OBJECT_INSERT(OBJECT_AGG(' || LISTAGG(target_column_names::STRING, ', ') || ', MD5(CONCAT(' || LISTAGG(target_column_names::STRING, ', ') || '))), ' || LISTAGG(target_column_names::STRING, ', ') || ', ''hash_key'')
    FROM ' || target_table_name || '
  ' INTO target_hashes;

  -- Generate Hash Key for Source Table
  EXECUTE IMMEDIATE '
    SELECT OBJECT_INSERT(OBJECT_AGG(' || LISTAGG(source_column_names::STRING, ', ') || ', MD5(CONCAT(' || LISTAGG(source_column_names::STRING, ', ') || '))), ' || LISTAGG(source_column_names::STRING, ', ') || ', ''hash_key'')
    FROM ' || source_table_name || '
  ' INTO source_hashes;

  -- Validate Insert Records
  insert_records := (
    SELECT key_column
    FROM TABLE(flatten(source_hashes))
    WHERE NOT target_hashes:key_column IS NOT NULL
  );

  -- Validate Update Records
  update_records := (
    SELECT s.key_column
    FROM TABLE(flatten(source_hashes)) s
    JOIN TABLE(flatten(target_hashes)) t ON s.key_column = t.key_column
    WHERE s.hash_key <> t.hash_key
  );

  -- Return Validation Results
  RETURN PARSE_JSON('{
    "insert_records": ' || TO_JSON(insert_records) || ',
    "update_records": ' || TO_JSON(update_records) || '
  }');
END;
$$;



CALL VALIDATE_INSERT_UPDATE_RECORDS();





























--------------------------------------------------------










ata Completeness:
Measure the completeness of data for different tables or key entities in the data warehouse.
Calculate the percentage of missing or null values for important fields.
sql
Copy code
SELECT 
    table_name,
    (COUNT(*) - COUNT(column_name)) / COUNT(*) AS completeness_percentage
FROM 
    your_table
GROUP BY 
    table_name;
Data Accuracy:
Assess the accuracy of data by comparing it against trusted data sources or reference data.
Calculate data accuracy metrics, such as error rates or data validation results.
sql
Copy code
SELECT 
    (COUNT(*) - SUM(CASE WHEN column_name = reference_value THEN 1 ELSE 0 END)) / COUNT(*) AS accuracy_rate
FROM 
    your_table;
Data Consistency:
Evaluate the consistency of data across different tables or data sources in the data warehouse.
Check for inconsistencies in attribute values or referential integrity.
sql
Copy code
SELECT 
    column_name,
    COUNT(DISTINCT column_name) AS unique_values
FROM 
    your_table
GROUP BY 
    column_name;
Data Timeliness:
Monitor the timeliness of data updates in the data warehouse.
Track the time lag between the source system data updates and data availability in the data warehouse.
sql
Copy code
SELECT 
    table_name,
    MAX(warehouse_timestamp_column) - MAX(source_system_timestamp_column) AS data_lag
FROM 
    your_table
GROUP BY 
    table_name;
Data Duplication:
Identify and track duplicate records in the data warehouse.
Count the number of duplicate records based on unique identifiers.
sql
Copy code
SELECT 
    column_name,
    COUNT(*) AS duplicate_count
FROM 
    your_table
GROUP BY 
    column_name
HAVING 
    COUNT(*) > 1;
Data Integrity:
Ensure the integrity of the data through constraints and business rules.
Validate data against predefined rules and identify violations.
sql
Copy code
SELECT 
    column_name,
    COUNT(*) AS violation_count
FROM 
    your_table
WHERE 
    column_name NOT IN (valid_values)
GROUP BY 
    column_name;
Data Load and Processing Status:
Monitor the status of data loads and processing jobs in the data warehouse.
Track the success rates, processing times, and any errors or failures encountered during data processing.
sql
Copy code
SELECT 
    job_name,
    CASE WHEN status = 'success' THEN 1 ELSE 0 END AS success,
    CASE WHEN status = 'failure' THEN 1 ELSE 0 END AS failure,
    processing_time
FROM 
    your_job_table;
Data Quality Trends:
Analyze data quality trends over time to identify patterns or anomalies.
Visualize metrics such as completeness, accuracy, or duplication rates over different time periods.
sql
Copy code
SELECT 
    DATE_TRUNC('month', timestamp_column) AS month,
    AVG(completeness_percentage) AS avg_completeness,
    AVG(accuracy_rate) AS avg_accuracy
FROM 
    your_table
GROUP BY 
    month;
Exception and Error Management:
Monitor and track data quality exceptions, errors, or anomalies.
Log and categorize data quality issues and track their resolution status.
sql
Copy code
SELECT 
    error_type,
    COUNT(*) AS error_count
FROM 
    your_error_table
GROUP BY 
    error_type;
Data Profiling and Sampling:
Perform data profiling and sampling techniques to assess data quality.
Generate summary statistics, data distributions, or outlier analysis.
sql
Copy code
SELECT 
    column_name,
    MIN(column_name) AS min_value,
    MAX(column_name) AS max_value,
    AVG(column_name) AS avg_value,
    COUNT(*) AS record_count
FROM 
    your_table
GROUP BY 
    column_name;
These are just example SQL queries to illustrate the concepts. You will need to adapt them to your specific database schema and requirements.




